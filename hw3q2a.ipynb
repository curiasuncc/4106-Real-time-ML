{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/curiasuncc/4106-Real-time-ML/blob/main/hw3q2a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcqnH_J92bn6"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#torch.set_printoptions(edgeitems=2)\n",
        "#torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSmbRUOy2bn7"
      },
      "outputs": [],
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6RRTYxI2bn8",
        "outputId": "47b74562-0a90-4461-defb-b440d3501c8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "data_path = '../data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mp9r6Qhh2bn8",
        "outputId": "ab1918b0-8d3b-447f-b69e-a006157c4fd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EL4XwvftkYcF",
        "outputId": "3221f94c-e9af-4e92-91a7-5af0b88af8cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on device cuda.\n"
          ]
        }
      ],
      "source": [
        "device = (torch.device('cuda') if torch.cuda.is_available()\n",
        "          else torch.device('cpu'))\n",
        "print(f\"Training on device {device}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kuT0qPD2boF"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)  # <1>\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZABI9Jx2boI"
      },
      "outputs": [],
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, n_chans):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
        "                              padding=1, bias=False,device=device)  # <1>\n",
        "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans,device=device)\n",
        "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
        "                                      nonlinearity='relu')  # <2>\n",
        "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
        "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.batch_norm(out)\n",
        "        out = torch.relu(out)\n",
        "        return out + x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyXdNIEw2boI"
      },
      "outputs": [],
      "source": [
        "class NetResDeep(nn.Module):\n",
        "    def __init__(self, n_chans1=32, n_blocks=10):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1,device=device)\n",
        "        self.resblocks = nn.Sequential(\n",
        "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
        "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32,device=device)\n",
        "        self.fc2 = nn.Linear(32, 10,device=device)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = self.resblocks(out)\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
        "        out = torch.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qA66zGO7kYcH"
      },
      "outputs": [],
      "source": [
        "CUDA_LAUNCH_BLOCKING=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "et5RvUcx2boJ",
        "outputId": "b5bc3573-57c3-42f1-b2f3-4462cb5fa1e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-03-30 01:11:51.023457 Epoch 1, Training loss 1.6992853474434075\n",
            "2022-03-30 01:14:22.413575 Epoch 10, Training loss 0.8871410553107786\n",
            "2022-03-30 01:17:15.719491 Epoch 20, Training loss 0.6869812177117828\n",
            "2022-03-30 01:20:04.882463 Epoch 30, Training loss 0.5481699682257669\n",
            "2022-03-30 01:22:53.145434 Epoch 40, Training loss 0.43825479131906536\n",
            "2022-03-30 01:25:40.802049 Epoch 50, Training loss 0.3516585431954897\n",
            "2022-03-30 01:28:28.495563 Epoch 60, Training loss 0.2812145820549687\n",
            "2022-03-30 01:31:16.558245 Epoch 70, Training loss 0.21719312540176886\n",
            "2022-03-30 01:34:04.663230 Epoch 80, Training loss 0.1708471742851655\n",
            "2022-03-30 01:36:55.621617 Epoch 90, Training loss 0.1299540400195419\n",
            "2022-03-30 01:39:45.403548 Epoch 100, Training loss 0.12276119698860856\n",
            "2022-03-30 01:42:36.381279 Epoch 110, Training loss 0.09723993261461444\n",
            "2022-03-30 01:45:24.605376 Epoch 120, Training loss 0.08870302495675261\n",
            "2022-03-30 01:48:12.951147 Epoch 130, Training loss 0.0683490005929185\n",
            "2022-03-30 01:51:03.141259 Epoch 140, Training loss 0.05794373764227742\n",
            "2022-03-30 01:53:51.757307 Epoch 150, Training loss 0.0149894694961748\n",
            "2022-03-30 01:56:41.403676 Epoch 160, Training loss 0.004934616174603648\n",
            "2022-03-30 01:59:30.354711 Epoch 170, Training loss 0.02252697706495857\n",
            "2022-03-30 02:02:22.409697 Epoch 180, Training loss 0.006459540387084398\n",
            "2022-03-30 02:05:10.167772 Epoch 190, Training loss 0.0062329580290112025\n",
            "2022-03-30 02:07:57.853309 Epoch 200, Training loss 0.03036239213394144\n",
            "2022-03-30 02:10:46.885750 Epoch 210, Training loss 0.0050489010809681946\n",
            "2022-03-30 02:13:34.990492 Epoch 220, Training loss 0.002304614160184289\n",
            "2022-03-30 02:16:23.021261 Epoch 230, Training loss 0.020959292386618\n",
            "2022-03-30 02:19:10.771207 Epoch 240, Training loss 0.003733099523179657\n",
            "2022-03-30 02:21:58.519993 Epoch 250, Training loss 0.0017737148445658743\n",
            "2022-03-30 02:24:46.922612 Epoch 260, Training loss 0.0013902615774498063\n",
            "2022-03-30 02:27:35.433679 Epoch 270, Training loss 0.0014138788061720097\n",
            "2022-03-30 02:30:23.000724 Epoch 280, Training loss 0.0011860328036315186\n",
            "2022-03-30 02:33:10.924362 Epoch 290, Training loss 0.010809776038699604\n",
            "2022-03-30 02:35:58.503370 Epoch 300, Training loss 0.0029286937779382815\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "model = NetResDeep(n_chans1=32, n_blocks=10).to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 300,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "#all_acc_dict[\"res deep\"] = validate(model, train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ft0nN1yy2boF",
        "outputId": "fe4a365e-7fab-4618-ed6d-718803877d65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy train: 0.71\n",
            "Accuracy val: 0.55\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "all_acc_dict = collections.OrderedDict()\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    accdict = {}\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device=device)\n",
        "                labels = labels.to(device=device)\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
        "                total += labels.shape[0]\n",
        "                correct += int((predicted == labels).sum())\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "        accdict[name] = correct / total\n",
        "    return accdict\n",
        "\n",
        "all_acc_dict[\"res deep\"] = validate(model, train_loader, val_loader)"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "colab": {
      "name": "hw3q2a.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}