{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/curiasuncc/4106-Real-time-ML/blob/main/Hw3_Q1b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJguQWCYAaWF"
      },
      "source": [
        "libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kK2fjdbxJLia"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "#torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzxx38w5JLie"
      },
      "outputs": [],
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_QDWU2nJLie",
        "outputId": "1197c507-7d40-4c8e-f7eb-c27f6e0ae72f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "data_path = '../data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rie61C_0JLif",
        "outputId": "1116204a-c994-4af4-b065-72170c4caff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PcfnqlGGvvq"
      },
      "outputs": [],
      "source": [
        "#model = Net()\n",
        "\n",
        "#numel_list = [p.numel() for p in model.parameters()]\n",
        "#sum(numel_list), numel_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qMF6p0IJLio"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1,device=device)\n",
        "        self.conv2 = nn.Conv2d(32, 16, kernel_size=3, padding=1,device=device)\n",
        "\n",
        "        self.conv3=nn.Conv2d(16, 16, kernel_size=3, padding=1,device=device)\n",
        "\n",
        "        self.fc1 = nn.Linear(4 * 4 * 16, 32,device=device)\n",
        "        self.fc2 = nn.Linear(32, 10,device=device)\n",
        "        #self.fc3 = nn.Linear(16,10,device=device)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "\n",
        "        out = F.max_pool2d(torch.relu(self.conv3(out)), 2)\n",
        "\n",
        "        out = out.view(-1, 4 * 4 * 16)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F51T-FS9JLio"
      },
      "outputs": [],
      "source": [
        "#model = Net()\n",
        "#model(img.unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7w89S0JJLiq"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)  # <1>\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTAutb_QWrPg",
        "outputId": "e6f57e93-6563-4825-936d-2b9b1bef372e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on device cuda.\n"
          ]
        }
      ],
      "source": [
        "device = (torch.device('cuda') if torch.cuda.is_available()\n",
        "          else torch.device('cpu'))\n",
        "print(f\"Training on device {device}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9K71XjyHLaa"
      },
      "outputs": [],
      "source": [
        "#CUDA_LAUNCH_BLOCKING=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "w8qdfc1yJLiq",
        "outputId": "ceb1542d-7e98-4410-b0c9-db1535718c31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-03-29 20:08:23.714152 Epoch 1, Training loss 2.1951829376428025\n",
            "2022-03-29 20:10:57.365567 Epoch 10, Training loss 1.1823122132464747\n",
            "2022-03-29 20:13:45.489661 Epoch 20, Training loss 0.9125960678853038\n",
            "2022-03-29 20:16:38.168900 Epoch 30, Training loss 0.8037290882957561\n",
            "2022-03-29 20:19:31.389770 Epoch 40, Training loss 0.73510301639052\n",
            "2022-03-29 20:22:22.250309 Epoch 50, Training loss 0.6896011519538777\n",
            "2022-03-29 20:25:15.177921 Epoch 60, Training loss 0.6529423982819633\n",
            "2022-03-29 20:28:08.156812 Epoch 70, Training loss 0.6240286410159772\n",
            "2022-03-29 20:31:01.796483 Epoch 80, Training loss 0.6000068468587173\n",
            "2022-03-29 20:33:55.930832 Epoch 90, Training loss 0.578468315436712\n",
            "2022-03-29 20:36:49.809258 Epoch 100, Training loss 0.5585739258724405\n",
            "2022-03-29 20:39:43.463890 Epoch 110, Training loss 0.5434207306112475\n",
            "2022-03-29 20:42:35.999515 Epoch 120, Training loss 0.5271323822876987\n",
            "2022-03-29 20:45:28.188139 Epoch 130, Training loss 0.5126166265372121\n",
            "2022-03-29 20:48:16.106116 Epoch 140, Training loss 0.4992113979271306\n",
            "2022-03-29 20:51:06.264817 Epoch 150, Training loss 0.48712676281438155\n",
            "2022-03-29 20:53:59.552522 Epoch 160, Training loss 0.4762689551467176\n",
            "2022-03-29 20:56:51.986418 Epoch 170, Training loss 0.46467674323512465\n",
            "2022-03-29 20:59:43.186223 Epoch 180, Training loss 0.4557413813060202\n",
            "2022-03-29 21:02:29.177348 Epoch 190, Training loss 0.44688949221387847\n",
            "2022-03-29 21:05:14.176588 Epoch 200, Training loss 0.43796354456021047\n",
            "2022-03-29 21:07:49.802430 Epoch 210, Training loss 0.4327803407140705\n",
            "2022-03-29 21:10:31.045880 Epoch 220, Training loss 0.4245691524670862\n",
            "2022-03-29 21:13:16.160139 Epoch 230, Training loss 0.4211012996599802\n",
            "2022-03-29 21:16:01.060304 Epoch 240, Training loss 0.41019745578851236\n",
            "2022-03-29 21:18:44.384562 Epoch 250, Training loss 0.40680931613344673\n",
            "2022-03-29 21:21:32.002862 Epoch 260, Training loss 0.39988060331786685\n",
            "2022-03-29 21:24:25.905830 Epoch 270, Training loss 0.3983133699925964\n",
            "2022-03-29 21:27:10.498057 Epoch 280, Training loss 0.39052621578164115\n",
            "2022-03-29 21:29:51.895468 Epoch 290, Training loss 0.3884589007634031\n",
            "2022-03-29 21:32:33.201928 Epoch 300, Training loss 0.3836920079596512\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "model = Net().to(device=device)  # <1>\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 300,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXDw1Ae_JLiq",
        "outputId": "bab5eba5-8243-4405-99ef-92fa41122b23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy train: 0.84\n",
            "Accuracy val: 0.66\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "all_acc_dict = collections.OrderedDict()\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    accdict = {}\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device=device)\n",
        "                labels = labels.to(device=device)\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
        "                total += labels.shape[0]\n",
        "                correct += int((predicted == labels).sum())\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "        accdict[name] = correct / total\n",
        "    return accdict\n",
        "\n",
        "all_acc_dict[\"baseline\"] = validate(model, train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOqs-yyX2GZg"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "7part2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}